---
layout:     post
date:       2022-3-28
author:     "kk"
title: "数据库"
header-style: text
tags:
  - 基础
---



- left join， right join， inner join

  left join 以左表为基准进行匹配，right join以右表为基准进行匹配，inner join 只筛选出满足匹配条件的项，inner join的条数肯定是小于等于left join或right join的

  对于left join，是针对左表中的每一条记录，查找右表，即使不满足匹配条件，也不会剔除，right join类似

  而inner join是会剔除不满足匹配条件的记录

- 读写锁(read write lock)

  允许多个进程读，只允许一个进程写。**注意：不光写进程之间是互斥的，而且读进程和写进程也是互斥的，即如果有进程在写，那么就不能读，如果有进程在读，那就不能写！！**

  读锁也叫做，共享锁，S锁d

  写锁也叫做，排他锁，X锁

  实现方式：使用两个信号量r、g实现，b表示写进程的数量

  ```
  // 初始化
  Set b to 0.
  r is unlocked.
  g is unlocked.
  
  -------------------------------
  读进程
  // 开始读
  Lock r.
  Increment b.
  If b = 1, lock g.
  Unlock r.
  
  // 结束读
  Lock r.
  Decrement b.
  If b = 0, unlock g.
  Unlock r.
  -------------------------------
  写进程
  // 开始写
  Lock g.
  
  // 结束写
  Unlock g.
  -------------------------------
  ```

  这种写法是读优先，即如果读进程多且块的话，会导致写进程一直无法获取g这个lock，导致写进程饥饿

  当然也有写优先，这样会导致读进程饥饿

  有一些机制去解决进程饥饿的问题

- redo log buffer、 undo buffer、read buffer、write buffer

  - mysql在读数据和写数据的时候，不是直接对硬盘里的表进行操作，因为这样会频繁地进行IO，导致效率很低。所以他会在内存中开辟一个空间作为缓存，有read buffer与write buffer。
  - 在读数据的时候，先去read buffer里读，read buffer里没有才会去磁盘里读。

  - 写的时候，先写入write buffer，等write buffer满了之后，再一次性写到磁盘里。

  - redo log buffer：事务中，每进行一次操作，都会在redo log buffer中记录一次。比如把A = 1 修改为 A = 2 然后修改 A = 3，那么redo log buffer里面记录的就是A = 2, A = 3的操作（**但实际上redo里面还会包含undo的内容，其顺序为：写undo的redo、写undo、修改数据页、写Redo**）。即通过redo，我们可以恢复出事务的每一步。在事务commit后，redo log buffer会写入到磁盘的redo log file里面（采用的是追加的方式），然后才是将内存中修改的数据写回到数据库的表中。

    考虑一种场景：当事务commit后，redo log file已经写入磁盘，在这个时候，突然停电了，导致数据没来得及写回数据库的表中，这个时候可以通过redo log file来进行恢复

  - undo log buffer：undo与redo相反，记录的是A = 1， A = 2的操作，即通过undo，我们可以对事务的每一步进行回退。undo log buffer也会定时写进磁盘里面。

- 脏读、幻读、不可重复读

  - 脏读：事务A读取了其他事务还未提交的数据。也即是说其他事务的未提交的更改对事务A是可见的。
  - 幻读：事务A进行了查询，返回了满足查询条件的一定数量的结果集，然后事务B添加或者删除了一些满足查询条件的数据，那么在事务B之后，在再进行查询，就会出现查询条目不一致的问题。
  - 不可重复读：事务A在不同时间读到的结果不一样。比如事务A最开始读到age = 10，然后事务B修改了age的值 age = 20，那么事务A如果在事务B提交后再读age的值，就变成了20。也就是说其他事务的提交对事务A是可见的。这个现象一般来说是正常的，因为别人都已经提交修改了，那么读到的是别人修改过的，也是可以理解的。但是有的时候，我们就是需要在某一时刻数据库的数据，这个时候就应该保留这一时刻下数据库的状态信息，就像照相机一样，拍下当时的状态，所以很形象地叫做快照（snapshot）

- 隔离级别（isolation level）

  事务A读，事务B写

  - read uncommited

    没有读锁，有行级写锁，写锁是直到事务结束释放。所以可以读到事务B还未提交的修改，出现脏读、幻读、不可重复读

  - read commited

    有行级读锁和行级写锁，读锁是一旦执行完读的语句就立马释放，而写锁是等事务结束才释放

    所以事务A不会读到未提交的修改，但是可以读到提交后的修改；

    所以不会出现脏读，会出现不可重复度和幻读

  - repeatable read

    有行级读锁和行级写锁，读锁是等事务结束才释放，而写锁也是等事务结束才释放

    此时对于某一行，在事务A进行过程中读和写不会同时进行，也就不会出现不可重复读的问题；但是因为这里的读锁、写锁都是基于行的，所以如果事务B插入了某些行，那么会导致事务A查询的时候条目不一致

  - serializable

    加表级读锁和表级写锁，都等到事务结束再释放

  造成这些现象的原因是，一是锁的粒度，二是锁的释放时间

- mysql 两种引擎：innodb、MyISAM
  - innodb支持事务，MyISAM不支持事务
  - innodb支持行级锁，MyISAM只支持表级锁
  - innodb中count操作需要扫描整张表，MyISAM由专门的存储位置（在没有where条件的前提下）。为什么innodb不用专门的地方去存储表的行数呢，因为innodb支持事务，所以在多线程情况下，不同线程看到的表的行数是不同的
  - innodb中采用的是聚簇索引，MyISAM采用非聚簇索引，两个引擎索引都是采用B+树实现。在innodb中，主键索引的叶子节点存放的就是行记录，辅助索引的叶子节点存放的是主键，因此根据辅助索引寻找数据的时候，先走辅助索引的B+树，找到对应的主键，然后走主键索引的B+树，走到叶子节点，找到对应的记录（这个过程叫做回表）；MyISAM中，主键索引，辅助索引的叶子节点存放的都是记录的物理位置。因此在做SELECT的时候，MyISAM会更快，因为它不需要再去走一遍主键索引的B+树

  https://www.cnblogs.com/jiawen010/p/11805241.html


- mysql中解决幻读
  - 当前读：在这种情况下，事务需要读到当前时刻的数据。采用的是next-key lock，next-key lock是由间隙锁（gap lock）和记录锁构成的。next-key lock是一个左开右闭区间，而gap lock是一个开区间。
  - 快照读：使用MVCC机制。MVCC只在read commited和repeatable read两个隔离级别下工作。每次对记录进行修改后，会将更改加入到undo log中，用来回滚这条记录。索引结点会记录最后一次修改该事务的事务ID以及指向上一个版本的指针。通过对比版本号，然后回滚来获取之前的快照

- 索引失效的情况
  
  
  - 在联合索引的场景下，查询条件不满足最左匹配原则。
  
    例如建立了(a,b,c)这样的联合索引，那么查询条件为a, ab,abc的时候才会走索引
  
  - 索引列参与了计算。这个时候改变了对应查询值，所以就不会走索引
  
  - 模糊查询的时候，模糊匹配的占位符位于条件的首部。
  
    例如：like '%abc'，like '%abc%'是不会走索引的，而like 'abc%'会走索引
  
  - 使用OR关键字时。OR连接的条件并不是都有索引。
  
    因为OR是所有条件都要满足，所以一旦有条件没有索引的时候，反正都要顺序扫描一遍
  
- 为什么使用id，而不是用学号来作为主键索引？

  - 因为id是递增的，有序的，而学号是无序的，在构建B+树的时候，有序会减少很多的树结构的调整，提高插入效率

- 为什么使用limit进行分页查询后，越到后面速度越慢？（称为“深分页“问题）

  因为mysql中limit offset，size（比如limit 10000，10），它并不是直接查询10000-10010的数据，而是查出10010条数据，然后丢弃前面的10000条数据，返回最后的10条数据，所以offset越大，查询的速度越慢。优化方式

  - 使用主键索引对数据做一遍筛选。select * from table where id > 10000 limit 10；这个时候通过索引先筛选一遍，然后再使用limit就很轻松了
  
- 哪些情况下需要索引，哪些情况下不需要索引？

  需要索引的情况

  - 主键自动建立唯一索引
  - 频繁作为查询条件的字段应该创建索引
  - 在需要经常进行范围搜素或者排序的列上建立索引，因为B+树底层的双向链表是有序的
  - 经常出现在where语句中的字段建立索引

  不需要索引的情况

  - 表记录太少
  - 经常增删改的表或者字段

- 不适合做索引的字段

  主要是因为需要频繁调整B+树，开销很大

  - 频繁变更的字段
  - 区分度较低的字段
  - 太长的字段
  - 无序的字段


- sql慢查询优化

  - 分析语句，是否加载了不必要的字段、数据
  - 分析sql执行过程（explain），查看是否命中索引
  - 如果表数据量太大，考虑分表
  - 利用缓存，减少查询次数

- 乐观锁与悲观锁
  - 悲观锁：比如数据库的行级锁、表级锁等都是悲观锁。适合写多读少。
  - 乐观锁：基于版本号或者时间戳进行修改。每次修改的时候会将版本号+1，而另一个事务如果也要进行修改需要比较自己所持有的上一次的版本号与当前版本号相比较，如果相等才能够进行修改，如果不能，则不能修改。适合读多写少


- count(1)、count(*)、count(主键)、count(列)

  count(expr)，是判断expr是否为空，如果expr不为空，那么计数器加1

  count(1) ：1总是非空的，所以会计算所有的行数。

  count(*)：  星号代表所有的列。因为一行不可能所有的列都为空，所以也是记录所有的行数。因此count(1)和count(星)从结果上来说没有区别

  count(列)：会判该列的key是否为空，如果key非null，计数器加1

- 缓存穿透、缓存击穿、缓存雪崩

  3种现象的本质原因都是缓存没有命中，需要到数据库里读数据。解决方式一是减少请求数，二是让请求极可能地走缓存

  - 缓存穿透(Cache penetration)：大量查询数据库中没有的数据。这个时候因为缓存里不可能存储数据库中没有的数据，所以缓存不命中，会去数据库里查询，频繁地进行IO操作。

    解决方式：

    - 缓存数据库里没有的数据的key

    - 使用bloom filter。bloom filter类似于哈希表，不过它并不存储具体的key，将key对应的元素标记为1，表示存在。由此看出bloom filter存在的问题是，当有正常的key也hash到跟异常的key同一个位置的时候，会导致误判

  - 缓存击穿（Cache breakdown）：在缓存当中的热门的数据刚好失效了（超出了有效时间），这个时候，缓存虽然命中，但是因为数据失效，还是会去数据库查询，频繁地进行IO操作。

    - 增加热门数据的存活时间，甚至不设置失效时间（条件是该数据不会被频繁改变）
    - 上锁。在缓存失效时，从数据库里更新数据，这个过程不允许任何请求去数据库里读取该失效的数据，等更新完成后，才让他们去缓存里读

  - 缓存雪崩：缓存击穿的升级版，大量的出现缓存失效的问题，一般原因有两个：大量的数据同一时间失效；redis直接挂掉了。

    - 流量削峰
    - 熔断限流
    - 主从机


## 底层结构

- 详细讲讲数据库表存放数据的底层结构

  - 对表项定义一个结构体，然后用结构体数组/链表来存储表

    好处是：实现简单

    坏处：需要遍历整个数组/链表 才能够找到符合条件的条目

  - 使用平衡二叉树存储

    好处：可以在log2n的复杂度下查询到条目

    坏处：每个节点只存储了一条记录，IO效率低下

  - 使用B树

    B树中，每个节点可以存放多条数据，这样就可以一次IO读入多条数据

    缺点是：每个节点包含了键值和数据，导致在查找的时候，数据量大的时候，每个节点不一定一次IO就能够读完，可能要多次IO

    ![img](https://img-blog.csdnimg.cn/20200714155537906.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjYwODU3OQ==,size_16,color_FFFFFF,t_70#pic_center)

  - B+树

    相比于B树，B+树节点只记录键值，所以每个结点，少量IO就可以读取更多的键值，提高了查找效率。并且最后数据使用**双向链表**按序连接起来，方便进行范围查找

    ![B+树](https://img-blog.csdnimg.cn/20200715094906904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjYwODU3OQ==,size_16,color_FFFFFF,t_70#pic_center)

- 聚簇索引与非聚簇索引

  以innodb引擎为例：nnoDB 底层存储结构为B+树， B树的每个节点对应innodb的一个page，page大小是固定的， 一般设为16k。其中非叶子节点只有键值，叶子节点包含数据。

  首先会根据唯一主键创建一颗B+树，叶子节点存放的是数据库里每行的数据

  而每对一个key设置索引，就又会新建一颗B+树

  但是这些B+树的叶子节点，不是记录的数据库每行的数据，而是记录了数据的主键。所以在根据非主键索引查找时，会先查对应的索引树，然后找到主键，然后再主键索引树上查找对应的数据

  
