---
layout:     post
date:       2022-4-14
author:     "kk"
title: "操作系统"
header-style: text
tags:
  - 面试
---



## 多进程/线程

- 就绪态、执行态、阻塞态

  <img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.pianshen.com%2Fimages%2F34%2Faff8698efae1299d611a54c7b23fa432.png&refer=http%3A%2F%2Fwww.pianshen.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1652489520&t=e4feee811a1129ab6a0112d5b34409f5" alt="img" style="zoom: 67%;" />

- 进程上下文切换会切换什么东西

  - cpu上的寄存器：pc寄存器、通用寄存器等
- 切换页表
  - 内核栈

- 进程调度策略

  - FCFS：first come first serve。先来先服务

  - 短作业优先。会预估作业的完成时间，选择时间较短的作业

  - 优先级调度算法

    - 抢占式：如果有更高优先级的进程带来，会让当前进程放弃掉cpu
    - 非抢占式

  - 高响应比优先：

    优先级 = （等待服务时间 + 	要求服务时间） /  要求服务时间

    它会先运行短作业，所以是短作业优先；

    当运行时间一样时，等待时间越长的先服务，因此实现了先来先服务；

    当长作业等待时间长时，优先级会提高，不会导致长作业一致得不到运行

  - 时间片轮转

  - 多级反馈队列调度算法

    有多个调度就绪队列，有着不同的优先级。在同一个队列中，实现先来先服务。只有当前面的所有队列都没进程的时候，才会进行当前队列的进程调度。

- 进程同步、异步

  - 进程同步：所谓同步，就是发出一个功能调用时，在没有得到结果之前，该调用就不返回或继续执行后续操作。

    简单来说，同步就是必须一件一件事做，等前一件做完了才能做下一件事。

  - 进程异步：异步与同步相对，当一个异步过程调用发出后，调用者在没有得到结果之前，就可以继续执行后续操作。当这个调用完成后，**一般通过状态、通知和回调来通知调用者**。对于异步调用，调用的返回并不受调用者控制。

    对于通知调用者的三种方式，具体如下：

    - 状态：即监听被调用者的状态（轮询），调用者需要每隔一定时间检查一次，效率会很低。

    - 通知：当被调用者执行完成后，发出通知告知调用者，无需消耗太多性能。（发送信号，PV操作）

    - 回调：与通知类似，当被调用者执行完成后，会调用调用者提供的回调函数。

- 并行与并发：

  并行的前提一定是有多个物理设备：比如多个cpu核心，这样每个进程就可以独占一个cpu，同时进行运算

  并发是在一个物理设备上，多个进程进行切换，达到共同使用这个设备的目的

  因为进程切换耗费太多资源，所以就引入了线程，线程切换的代价没有进程切换大

  同一个进程内的线程共享地址空间，进程是资源分配的最小单位（主要是内存），而线程是cpu调度的最小单位

  四核八线程是指：一共有4个cpu核心，每一个cpu核心当中有一套计算单元（ALU），以及两套其他单元（寄存器等），并不是所有的线程都会用到计算单元，所以可以提高运行的效率，但是提高幅度也不是很大，15%左右

  **并发就是别让cpu闲下来，尽量让他满负荷运行**

- 进程切换与线程切换

  进程切换会涉及到地址空间的切换，而同一个进程内的线程切换不需要，因为线程共享进程的地址空间

  描述进程的是PCB（process control block），描述线程的是TCB（Thread control block）

- 在linux中，每个进程（**更准确地说是每个线程**）在创建完之后，会分别在用户空间和内核空间，给线程分配一个栈，分别叫做用户栈与内核栈。内核栈的最底部，存放的是线程的TCB信息，linux中使用一个thread_info结构体来进行描述，而进程PCB是用task_struct来进行描述

- 模式切换：用户态到内核态

  保存cpu上某些寄存器的内容（段寄存器内容不需要保存，PC，SP,BP以及一些通用寄存器内容需要保存）到PCB块，然后让PC寄存器跳转到内核的指令进行执行

  线程切换：

  先要进行模式切换，进入内核态，保存cpu上某些寄存器的内容到TCB块（线程共享进程的地址空间，所以段寄存器、TLB快表等是不会改变的）然后加载另一个线程的TCB块

  进程切换：

  先要进行模式切换，进入内核态，保存cpu上所有寄存器的内容到PCB，加载另一个PCB（此时TLB快表需要重新刷新），所以进程切换开销最大

  

## 内存管理

- 虚拟地址、物理地址

  如果直接让程序访问物理地址，不同的程序可能会使用相同的物理地址，导致冲突。虚拟地址隔绝了进程，每个进程有自己的虚拟地址，然后由操作系统将虚拟地址映射到物理地址

  以32位操作系统为例，一个进程可用的虚拟地址位4G，其中1G给内核，3G给用户空间，这里都是虚拟地址。但是对于内核虚拟地址来说，它映射到物理空间，仅仅是很简单的加上一个offset，**也就是说内核虚拟空间到物理空间的映射是固定的，是一个线性映射。而用户空间虚拟地址的映射是一个动态映射，同一个虚拟地址在不同时刻可能映射到不同的物理地址上。**

- 内存管理的进化史

  - 最开始，给每个进程分配连续的物理空间，这样的问题就是，会出现很多的内存碎片

  - 然后，把每个进程的虚拟地址分成不同的段，段表中记录每个段的物理地址，在地址映射的时候，段内是连续的，段可以映射到不同地方，这样就可以让段塞进一些内存碎片里。**但是仍然存在某些碎片无法得到利用**

  - 接着，把每个进程的虚拟地址空间分成页（4KB），页表记录虚拟页号与物理页号的对应关系，在地址映射的时候，把每页映射到不同的地方，这样就可以更加充分地利用小空间。

    以32位系统为例：每页4KB，一共有2^20页，页表项需要记录虚拟页号与物理页号的对应关系，每个页表项需要4B（因为虚拟页号可以用数组的下标来表示，那就不用占据空间了，20位物理页号在加上一些控制信息，然后对其到4B），那么一共就需要4MB的连续空间来储存页表，这样的连续空间也不一定好找。

    然后就有了多级页表，可以使页表存储在不连续的空间上，**但需要的空间总数不会减少，反而因为要存储多级页表，会增加一些空间。但使用多级页表的好处，就是可以离散化之前完整的页表，有利于页表的替换和更改**

    记住：每一个进程都有一个页表，因此极端情况下，每个进程都需要4MB去记录虚拟地址到物理地址的映射

    但是分页也有缺点：不好做访问控制，比如访问的地址已经超出了某个范围，如果有分段的话，可以直接看偏移地址是否超出了段的界限，而分页必须要查询页表，然后才能判断是否访问无效

  - 最后，就是段页式了，将段和页结合起来，先逻辑上分段，然后再进行分页

- cpu访问内存的总过程

  首先要记住：**cpu获得的总是虚拟地址，虚拟地址到物理地址的转换由内存管理单元MMU（memory management unit）完成**

  - cpu拿到虚拟地址，取出虚拟地址的页号，查询块表TLB（translation lookaside buffer），如果有虚拟页号对应的物理页号，直接将虚拟地址转成物理地址。然后访问cache，如果在cache中，直接读入cache中的内容，如果不在cache中，就访问内存。
  - 如果没有在TLB中，检查访问的地址是否超出所在段的范围，如果超过了，报段越界的错误
  - 如果没有段越界，查询段号对应的一级页表的地址，访问一级页表，然后逐级访问页表，直到查询到对应的虚拟页号
  - 查询到虚拟页号，页表项中有记录当前虚拟页号所对应的物理页号的状态，如果该物理页没在内存当中，触发缺页中断，os处理中断，把该页换入cache，并且把物理页号填入TLB中，中断处理完，cpu继续访问该物理地址，就直接去TLB中取数据。如果没有触发缺页中断，直接将虚拟地址转成物理地址，进行访问

- 低级的单片机中是没有OS和MMU的，所以访问的直接是真实的物理地址

- LRU（least recently used）最近最少使用。一般用于内存页、cache的淘汰，未经常使用的内存页、cache会被换出

  底层的数据结构如下：

  - 使用双向链表连接页。双向链表的头部表示刚刚访问的页，而尾部表示很久没访问的页
  - 再使用一个hash表来记录链表里页号和对应的地址

     查询过程如下：

  - 查询页号是否在hash表中，如果在，就可以得到对应的地址，然后进行访问，并把该节点移动到双向链表的头部

    如果不在，从硬盘中读取该页的内容，插入到双向链表的头部，然后删除尾部的节点，并在hash表中页同时删除该节点，并记录新插入的节点的页号和地址

## IO

在网络编程中，传输的数据首先会存储在内核区的socket缓冲区中，然后再将数据从内核区复制到用户进程内存中。socket在创建的时候可以设置模式，阻塞式是要等所有数据准备好才能进行复制，非阻塞式无需等所有数据准备好，只要有数据就能进行复制

```
ssize_t recvfrom(int socket, void *restrict buffer, size_t length,
       int flags, struct sockaddr *restrict address,
       socklen_t *restrict address_len);
```

socket：指明socket file descriptor，即是要读取哪一个socket缓冲区里的内容

- BIO(blocking IO)

  用户进程调用recvfrom，从用户态切换到核心态，用户进程会一直阻塞，直到socket中的数据准备好，并且复制到用户空间中

  <img src="https://upload-images.jianshu.io/upload_images/3299509-ab82637c23095dc1.png?imageMogr2/auto-orient/strip|imageView2/2/w/1184/format/webp" alt="img" style="zoom:50%;" />

- NIO(nonblocking IO)

  与NIO不同，用户进程不会一直等待数据准备好，而是采用轮询的方式，不断查询数据是否准备好

  <img src="https://upload-images.jianshu.io/upload_images/3299509-2bd113dcb8421afb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1168/format/webp" alt="img" style="zoom:50%;" />

- IO multiplexing

  NIO中，用户进程频繁调用recvfrom，会频繁进行用户态核心态的切换，效率很低。所以，用户进程委托select进行查询，select是一个内核级别的操作，性能比较高。

  形式上与BIO很像，区别在于

  - select可以同时监控多个socket
  - select不用等待socket中的数据准备完毕，而是只要有数据就告知用户进程调用recvfrom进行复制（此时socket要设置为非阻塞式）

  <img src="https://upload-images.jianshu.io/upload_images/3299509-84bef1a7cdf11eea.png?imageMogr2/auto-orient/strip|imageView2/2/w/1128/format/webp" alt="img" style="zoom:50%;" />

  select、poll、epoll区别

  - select：

    ```
           int select(int nfds, fd_set *restrict readfds,
                      fd_set *restrict writefds, fd_set *restrict exceptfds,
                      struct timeval *restrict timeout);
    ```

    select可以监控多个socket，在调用select函数时，需要传入监控的socket的文件描述符（file descriptor，fd），select中文件描述符。fd_set是文件描述符的数组，在调用select函数时，该数组会复制到内核空间中。该数组长度是有限的，所以select监视的socket也是有限的

    select通过遍历的方式，查询监控的所有socket是否有数据

  - poll：与select大致相同，但是poll在数组复制到内核空间时，是用链表进行表示的，所以poll监控的socket没有限制

  - epoll：与select不同，epoll不通过遍历方式主动查询所有socket，而是socket有数据后，通知epoll

- AIO(asynchronous IO)

  IO multiplexing中，用户进程还是会阻塞在select以及数据复制过程，全部委托给aio_read，让它全权负责查询socket以及数据的复制，等待一切都做完了才通知用户进程，用户进程在整个过程当中是不会阻塞的

  <img src="https://upload-images.jianshu.io/upload_images/3299509-1b43f561f70f5ba3.png?imageMogr2/auto-orient/strip|imageView2/2/w/1176/format/webp" alt="img" style="zoom:50%;" />

## 文件管理

- 文件管理与内存管理基本的思路是一样的。磁盘也将物理空间分成了很多个大小一样的物理块。操作系统在保存一个文件的时候，经过了下面的步骤：

  - 维护一个文件控制块（file control block，FCB），包含了文件的权限控制，文件所属用户，所属组，文件大小等信息

    <img src="https://ithelp.ithome.com.tw/upload/images/20181111/20112132VY8aiIsx9I.png" alt="iT 邦幫忙::一起幫忙解決難題，拯救IT 人的一天" style="zoom:50%;" />

  - 将整个文件分成若干个逻辑块

  - 每个逻辑块写入对应的物理块

  综上所述，**一个文件的写入过程就是将逻辑记录打包成一个或者多个物理块，一个文件的读入过程就是将一个或者多个物理块解包成逻辑记录的过程。**





## CPU

- 寄存器

  - 段寄存器：

    ```
     CS——代码段寄存器(Code Segment Register)，其值为代码段的段值；
    
     DS——数据段寄存器(Data Segment Register)，其值为数据段的段值；
    
     ES——附加段寄存器(Extra Segment Register)，其值为附加数据段的段值；
    
     SS——栈段寄存器(Stack Segment Register)，其值为堆栈段的段值；
    
     FS——附加段寄存器(Extra Segment Register)，其值为附加数据段的段值；
    
     GS——附加段寄存器(Extra Segment Register)，其值为附加数据段的段值。
    ```

  - 指令寄存器

    IR（instruction register）：存放的是从内存中取出来的指令

  - 栈指针寄存器

    SP（stack pointer）：栈顶指针

    BP（base pointer）：栈底指针

  - 程序计数器

    PC（program count）：下一条指令的地址

  - 通用寄存器

- 缓存（cache）

  cache中存储的是经常使用的页

- 快表（TLB）

  快表存储的时，经常使用的 虚拟页号到物理页号的映射

  cpu读取内存的过程[^1]：

  物理cache：访问TLB --> 访问页表 ---> 访问cache ---> 访问内存

  逻辑cache：访问cache --> 访问TLB --> 访问页表 ---> 访问内存

<img src="http://jcf94.com/download/2018-09-04-cache-location.jpg" alt="img" style="zoom: 33%;" />



## DMA

Direct Memory Access：直接存储器访问



## 启动过程

- 计算机启动时，进行了哪些步骤？
  - 主板通电，向cpu供电，等cpu电压稳定后，cpu从ROM里面读取BIOS（basic input/output system）程序
  - BIOS检查硬件设备
  - BIOS从硬盘中加载操作系统
  - 然后操作系统接管计算机



[^1]: [细说Cache-L1/L2/L3/TLB](https://zhuanlan.zhihu.com/p/31875174)

