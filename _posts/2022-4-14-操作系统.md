---
layout:     post
date:       2022-4-14
author:     "kk"
title: "操作系统"
header-style: text
tags:
  - 面试
---





## 进程管理

- 就绪态、执行态、阻塞态

  <img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.pianshen.com%2Fimages%2F34%2Faff8698efae1299d611a54c7b23fa432.png&refer=http%3A%2F%2Fwww.pianshen.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1652489520&t=e4feee811a1129ab6a0112d5b34409f5" alt="img" style="zoom: 67%;" />

- 用户态与核心态？

  - `内核态`：处于内核态的 CPU 可以访问任意的数据，包括外围设备，比如网卡、硬盘等，处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况，一般处于特权级 0 的状态我们称之为内核态。
  - `用户态`：处于用户态的 CPU 只能受限的访问内存，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。
  - 用户态到和核心态的切换：操作系统执行系统调用，切换到核心态（trap指令）

- 并行与并发？

  并行：多个事件同一时刻发生

  并发：多个事件同一时间间隔发生，但在某一时刻上只有一个事件在发生

  例子：多核cpu是并行，而在单个cpu上是并发

- 进程与线程的区别？

  - 进程是资源分配的最小单位，而线程是 CPU 调度的最小单位；
  - 创建进程或撤销进程，系统都要为之分配或回收资源，操作系统开销远大于创建或撤销线程时的开销；
  - 不同进程地址空间相互独立，同一进程内的线程共享同一地址空间。一个进程的线程在另一个进程内是不可见的；
  - 进程间不会相互影响，而一个线程挂掉将可能导致整个进程挂掉；

- 为什么需要线程？

  - 进程在同一时间只能干一件事情；
  - 进程在执行的过程中如果阻塞，整个进程就会被挂起，即使进程中有些工作不依赖与等待的资源，仍然不会执行。

- 进程上下文切换会切换什么东西

  - cpu上的寄存器：pc寄存器、通用寄存器等
  - 切换页表
  - 内核栈

- 页面置换算法

  - OPT（optimal）：最佳页面置换算法。选择未来最长时间不被使用的页面被替换。因为我么无法预知进程未来使用的页面，所以只是理想情况，不能实际实现

  - FIFO（First in，First out）：总是淘汰最先进入内存的页面

  - LRU（least Recently Used）：最近最长未使用。淘汰掉最近最长时间没有被使用的页面，采用双向链表实现

  - LFU（least Frequently Used）：最少使用。会选择之前时间段种使用最少的页面淘汰

    缺页中断就是进程读取的页面没有在内存中，这个时候触发缺页中断，将页面读入内存

- 进程调度策略

  - FCFS：first come first serve。先来先服务

  - 短作业优先。会预估作业的完成时间，选择时间较短的作业

  - 优先级调度算法

    - 抢占式：如果有更高优先级的进程带来，会让当前进程放弃掉cpu
    - 非抢占式

  - 高响应比优先：

    优先级 = （等待服务时间  + 要求服务时间） /  要求服务时间

    它会先运行短作业，所以是短作业优先；

    当运行时间一样时，等待时间越长的先服务，因此实现了先来先服务；

    当长作业等待时间长时，优先级会提高，不会导致长作业一致得不到运行

  - 时间片轮转

  - 多级反馈队列调度算法

    有多个调度就绪队列，有着不同的优先级。在同一个队列中，实现先来先服务。只有当前面的所有队列都没进程的时候，才会进行当前队列的进程调度。

- 进程同步、异步

  - 进程同步：所谓同步，就是发出一个功能调用时，在没有得到结果之前，该调用就不返回或继续执行后续操作。

    简单来说，同步就是必须一件一件事做，等前一件做完了才能做下一件事。

  - 进程异步：异步与同步相对，当一个异步过程调用发出后，调用者在没有得到结果之前，就可以继续执行后续操作。当这个调用完成后，**一般通过状态、通知和回调来通知调用者**。对于异步调用，调用的返回并不受调用者控制。

    对于通知调用者的三种方式，具体如下：

    - 状态：即监听被调用者的状态（轮询），调用者需要每隔一定时间检查一次，效率会很低。

    - 通知：当被调用者执行完成后，发出通知告知调用者，无需消耗太多性能。（发送信号，PV操作）

    - 回调：与通知类似，当被调用者执行完成后，会调用调用者提供的回调函数。

- 进程间（IPC，InterProcess Communication）的通信方式？

  - 管道：

    - 它是半双工的，具有固定的读端和写端；

    - 它只能用于父子进程或者兄弟进程之间的进程的通信；

    - 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的 read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

  - 消息队列

    - 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符 ID 来标识；
    - 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级；
    - 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除；
    - 消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。

  - 信号量：信号量（semaphore）是一个计数器。用于实现进程间的**互斥与同步**，而不是用于存储进程间通信数据

  - 共享内存：指两个或多个进程共享一个给定的存储区

- 死锁产生的必要条件？

  - 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
  - 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。
  - 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
  - 环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链。

- 预防死锁？

  - 破坏请求条件：一次性分配所有资源，这样就不会再有请求了；
  - 破坏请保持条件：只要有一个资源得不到分配，也不给这个进程分配其他的资源：
  - 破坏不可剥夺条件：当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源；
  - 破坏环路等待条件：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反。

- 解除死锁？

  - 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程（但应该防止被挂起的进程长时间得不到资源）；
  - 撤销进程：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源（撤销的原则可以按进程优先级和撤销进程代价的高低进行）；
  - 进程回退：让一个或多个进程回退到足以避免死锁的地步。进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

- 并行与并发：

  并行的前提一定是有多个物理设备：比如多个cpu核心，这样每个进程就可以独占一个cpu，同时进行运算

  并发是在一个物理设备上，多个进程进行切换，达到共同使用这个设备的目的

  因为进程切换耗费太多资源，所以就引入了线程，线程切换的代价没有进程切换大

  同一个进程内的线程共享地址空间，进程是资源分配的最小单位（主要是内存），而线程是cpu调度的最小单位

  四核八线程是指：一共有4个cpu核心，每一个cpu核心当中有一套计算单元（ALU），以及两套其他单元（寄存器等），并不是所有的线程都会用到计算单元，所以可以提高运行的效率，但是提高幅度也不是很大，15%左右

  **并发就是别让cpu闲下来，尽量让他满负荷运行**

- 进程切换与线程切换

  进程切换会涉及到地址空间的切换，而同一个进程内的线程切换不需要，因为线程共享进程的地址空间

  描述进程的是PCB（process control block），描述线程的是TCB（Thread control block）

- 在linux中，每个进程（**更准确地说是每个线程**）在创建完之后，会分别在用户空间和内核空间，给线程分配一个栈，分别叫做用户栈与内核栈。内核栈的最底部，存放的是线程的TCB信息，linux中使用一个thread_info结构体来进行描述，而进程PCB是用task_struct来进行描述

- 模式切换：用户态到内核态

  保存cpu上某些寄存器的内容（段寄存器内容不需要保存，PC，SP,BP以及一些通用寄存器内容需要保存）到PCB块，然后让PC寄存器跳转到内核的指令进行执行

  线程切换：

  先要进行模式切换，进入内核态，保存cpu上某些寄存器的内容到TCB块（线程共享进程的地址空间，所以段寄存器、TLB快表等是不会改变的）然后加载另一个线程的TCB块

  进程切换：

  先要进行模式切换，进入内核态，保存cpu上所有寄存器的内容到PCB，加载另一个PCB（此时TLB快表需要重新刷新），所以进程切换开销最大


- 中断处理

  <img src="C:\Users\97691\OneDrive - zju.edu.cn\sjtukk.github.io\img\in-post\中断处理.png" alt="中断处理" style="zoom:150%;" />

- 僵尸进程

  **僵尸进程** 是子进程先于父进程退出后，子进程的 PCB 需要其父进程释放，但是父进程并没有释放子进程的 PCB，这样的子进程就称为僵尸进程。**僵尸进程实际上是一个已经死掉但并未释放 PCB 的进程**。

  清楚了僵尸进程的定义，我们再来了解一下它的产生。

  僵尸进程的产生 

  一个进程在调用 exit 命令结束自己的生命周期时，它并没有真正的被销毁，而是留下一个称为**僵尸进程（Zombie）** 的[数据]()结构（系统调用 exit 的作用是使进程退出，但也仅仅限于将一个正常的进程变成一个僵尸进程，并不能将其完全销毁）

- fork

  fork() 函数是创建一个新进程, 它的返回值分别是子进程中返回 0，父进程返回子进程的进程号 (PID)。我们就可以通过 fork()函数的返回值识别父子进程。

- 静态链接与动态链接？

  - 静态链接：在编译链接时直接将需要的执行代码拷贝到调用处，优点

    - 优点：就是在程序发布的时候就不需要的依赖库，也就是不再需要带着库一块发布，程序可以独立执行

    - 缺点：

      空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本； 

      更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。

  - 动态链接：动态链接就是在编译的时候不直接拷贝可执行代码，而是通过记录一系列符号和参数，在程序运行或加载时将这些信息传递给操作系统，操作系统负责将需要的动态库加载到内存中，然后程序在运行到指定的代码时，去共享执行内存中已经加载的动态库可执行代码，最终达到运行时连接的目的。优点是**多个程序可以共享同一段代码**，而不需要在磁盘上存储多个拷贝，缺点是由于是运行时加载，可能会影响程序的前期执行性能

    - 优点：

      共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多份副本，而是这多个程序在执行时共享同一份副本；

      更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

    - 缺点：

      性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。




## 内存管理

- 虚拟地址、物理地址

  如果直接让程序访问物理地址，不同的程序可能会使用相同的物理地址，导致冲突。虚拟地址隔绝了进程，每个进程有自己的虚拟地址，然后由操作系统将虚拟地址映射到物理地址

  以32位操作系统为例，一个进程可用的虚拟地址位4G，其中1G给内核，3G给用户空间，这里都是虚拟地址。但是对于内核虚拟地址来说，它映射到物理空间，仅仅是很简单的加上一个offset，**也就是说内核虚拟空间到物理空间的映射是固定的，是一个线性映射。而用户空间虚拟地址的映射是一个动态映射，同一个虚拟地址在不同时刻可能映射到不同的物理地址上。**

- 内存管理的进化史

  - 最开始，给每个进程分配连续的物理空间，这样的问题就是，会出现很多的内存碎片

  - 然后，把每个进程的虚拟地址分成不同的段，段表中记录每个段的物理地址，在地址映射的时候，段内是连续的，段可以映射到不同地方，这样就可以让段塞进一些内存碎片里。**但是仍然存在某些碎片无法得到利用**

  - 接着，把每个进程的虚拟地址空间分成页（4KB），页表记录虚拟页号与物理页号的对应关系，在地址映射的时候，把每页映射到不同的地方，这样就可以更加充分地利用小空间。

    以32位系统为例：每页4KB，一共有2^20页，页表项需要记录虚拟页号与物理页号的对应关系，每个页表项需要4B（因为虚拟页号可以用数组的下标来表示，那就不用占据空间了，20位物理页号在加上一些控制信息，然后对其到4B），那么一共就需要4MB的连续空间来储存页表，这样的连续空间也不一定好找。

    然后就有了多级页表，可以使页表存储在不连续的空间上，**但需要的空间总数不会减少，反而因为要存储多级页表，会增加一些空间。但使用多级页表的好处，就是可以离散化之前完整的页表，有利于页表的替换和更改**

    记住：每一个进程都有一个页表，因此极端情况下，每个进程都需要4MB去记录虚拟地址到物理地址的映射

    但是分页也有缺点：不好做访问控制，比如访问的地址已经超出了某个范围，如果有分段的话，可以直接看偏移地址是否超出了段的界限，而分页必须要查询页表，然后才能判断是否访问无效

  - 最后，就是段页式了，将段和页结合起来，先逻辑上分段，然后再进行分页。

- 段页式访问内存的过程

  - cpu拿到虚拟地址，访问段表，找到对应的段，然后找到这个段的页表地址
  - cpu访问页表，将虚拟地址翻译为物理地址
  - cpu访问物理地址，读出数据

- 分页与分段的区别？

  - 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的；（透明的意思是用户看不见）
  - 段的大小不固定，有它所完成的功能决定；页大大小固定，由系统决定；
  - 段向用户提供二维地址空间；页向用户提供的是一维地址空间；
  - 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。

- cpu访问内存的总过程

  首先要记住：**cpu获得的总是虚拟地址，虚拟地址到物理地址的转换由内存管理单元MMU（memory management unit）完成**

  - cpu拿到虚拟地址，取出虚拟地址的页号，查询块表TLB（translation lookaside buffer），如果有虚拟页号对应的物理页号，直接将虚拟地址转成物理地址。然后访问cache，如果在cache中，直接读入cache中的内容，如果不在cache中，就访问内存。
  - 如果没有在TLB中，检查访问的地址是否超出所在段的范围，如果超过了，报段越界的错误
  - 如果没有段越界，查询段号对应的一级页表的地址，访问一级页表，然后逐级访问页表，直到查询到对应的虚拟页号
  - 查询到虚拟页号，页表项中有记录当前虚拟页号所对应的物理页号的状态，如果该物理页没在内存当中，触发缺页中断，os处理中断，把该页换入cache，并且把物理页号填入TLB中，中断处理完，cpu继续访问该物理地址，就直接去TLB中取数据。如果没有触发缺页中断，直接将虚拟地址转成物理地址，进行访问

- 低级的单片机中是没有OS和MMU的，所以访问的直接是真实的物理地址

- LRU（least recently used）最近最少使用。一般用于内存页、cache的淘汰，未经常使用的内存页、cache会被换出

  底层的数据结构如下：

  - 使用双向链表连接页。双向链表的头部表示刚刚访问的页，而尾部表示很久没访问的页
  - 再使用一个hash表来记录链表里页号和对应的地址

     查询过程如下：

  - 查询页号是否在hash表中，如果在，就可以得到对应的地址，然后进行访问，并把该节点移动到双向链表的头部

    如果不在，从硬盘中读取该页的内容，插入到双向链表的头部，然后删除尾部的节点，并在hash表中页同时删除该节点，并记录新插入的节点的页号和地址







## 设备管理

在网络编程中，传输的数据首先会存储在内核区的socket缓冲区中，然后再将数据从内核区复制到用户进程内存中。socket在创建的时候可以设置模式，阻塞式是要等所有数据准备好才能进行复制，非阻塞式无需等所有数据准备好，只要有数据就能进行复制

```
ssize_t recvfrom(int socket, void *restrict buffer, size_t length,
       int flags, struct sockaddr *restrict address,
       socklen_t *restrict address_len);
```

socket：指明socket file descriptor，即是要读取哪一个socket缓冲区里的内容

- BIO(blocking IO)

  用户进程调用recvfrom，从用户态切换到核心态，用户进程会一直阻塞，直到socket中的数据准备好，并且复制到用户空间中

  <img src="https://upload-images.jianshu.io/upload_images/3299509-ab82637c23095dc1.png?imageMogr2/auto-orient/strip|imageView2/2/w/1184/format/webp" alt="img" style="zoom:50%;" />

- NIO(nonblocking IO)

  与NIO不同，用户进程不会一直等待数据准备好，而是采用轮询的方式，不断查询数据是否准备好

  <img src="https://upload-images.jianshu.io/upload_images/3299509-2bd113dcb8421afb.png?imageMogr2/auto-orient/strip|imageView2/2/w/1168/format/webp" alt="img" style="zoom:50%;" />

- IO multiplexing

  NIO中，用户进程频繁调用recvfrom，会频繁进行用户态核心态的切换，效率很低。所以，用户进程委托select进行查询，select是一个内核级别的操作，性能比较高。

  形式上与BIO很像，区别在于

  - select可以同时监控多个socket
  - select不用等待socket中的数据准备完毕，而是只要有数据就告知用户进程调用recvfrom进行复制（此时socket要设置为非阻塞式）

  <img src="https://upload-images.jianshu.io/upload_images/3299509-84bef1a7cdf11eea.png?imageMogr2/auto-orient/strip|imageView2/2/w/1128/format/webp" alt="img" style="zoom:50%;" />

  select、poll、epoll区别

  - select：

    ```
           int select(int nfds, fd_set *restrict readfds,
                      fd_set *restrict writefds, fd_set *restrict exceptfds,
                      struct timeval *restrict timeout);
    ```

    select可以监控多个socket，在调用select函数时，需要传入监控的socket的文件描述符（file descriptor，fd），select中文件描述符。fd_set是文件描述符的数组，在调用select函数时，该数组会复制到内核空间中。该数组长度是有限的，所以select监视的socket也是有限的

    select通过遍历的方式，查询监控的所有socket是否有数据

  - poll：与select大致相同，但是poll在数组复制到内核空间时，是用链表进行表示的，所以poll监控的socket没有限制

  - epoll：与select不同，epoll不通过遍历方式主动查询所有socket，而是socket有数据后，通知epoll

- AIO(asynchronous IO)

  IO multiplexing中，用户进程还是会阻塞在select以及数据复制过程，全部委托给aio_read，让它全权负责查询socket以及数据的复制，等待一切都做完了才通知用户进程，用户进程在整个过程当中是不会阻塞的

  <img src="https://upload-images.jianshu.io/upload_images/3299509-1b43f561f70f5ba3.png?imageMogr2/auto-orient/strip|imageView2/2/w/1176/format/webp" alt="img" style="zoom:50%;" />

## 文件管理

- 文件管理与内存管理基本的思路是一样的。磁盘也将物理空间分成了很多个大小一样的物理块。操作系统在保存一个文件的时候，经过了下面的步骤：

  - 维护一个文件控制块（file control block，FCB），包含了文件的权限控制，文件所属用户，所属组，文件大小等信息

    <img src="https://ithelp.ithome.com.tw/upload/images/20181111/20112132VY8aiIsx9I.png" alt="iT 邦幫忙::一起幫忙解決難題，拯救IT 人的一天" style="zoom:50%;" />

  - 将整个文件分成若干个逻辑块

  - 每个逻辑块写入对应的物理块

  综上所述，**一个文件的写入过程就是将逻辑记录打包成一个或者多个物理块，一个文件的读入过程就是将一个或者多个物理块解包成逻辑记录的过程。**





## CPU

- 寄存器

  - 段寄存器：

    ```
     CS——代码段寄存器(Code Segment Register)，其值为代码段的段值；
    
     DS——数据段寄存器(Data Segment Register)，其值为数据段的段值；
    
     ES——附加段寄存器(Extra Segment Register)，其值为附加数据段的段值；
    
     SS——栈段寄存器(Stack Segment Register)，其值为堆栈段的段值；
    
     FS——附加段寄存器(Extra Segment Register)，其值为附加数据段的段值；
    
     GS——附加段寄存器(Extra Segment Register)，其值为附加数据段的段值。
    ```

  - 指令寄存器

    IR（instruction register）：存放的是从内存中取出来的指令

  - 栈指针寄存器

    SP（stack pointer）：栈顶指针

    BP（base pointer）：栈底指针

  - 程序计数器

    PC（program count）：下一条指令的地址

  - 通用寄存器

- 缓存（cache）

  cache中存储的是经常使用的页

- 快表（TLB）

  快表存储的时，经常使用的 虚拟页号到物理页号的映射

  cpu读取内存的过程[^1]：

  物理cache：访问TLB --> 访问页表 ---> 访问cache ---> 访问内存

  逻辑cache：访问cache --> 访问TLB --> 访问页表 ---> 访问内存

<img src="http://jcf94.com/download/2018-09-04-cache-location.jpg" alt="img" style="zoom: 33%;" />



## DMA

Direct Memory Access：直接存储器访问



## 启动过程

- 计算机启动时，进行了哪些步骤？
  - 主板通电，向cpu供电，等cpu电压稳定后，cpu从ROM里面读取BIOS（basic input/output system）程序
  - BIOS检查硬件设备
  - BIOS从硬盘中加载操作系统
  - 然后操作系统接管计算机



[^1]: [细说Cache-L1/L2/L3/TLB](https://zhuanlan.zhihu.com/p/31875174)

